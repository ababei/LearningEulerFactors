{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the terminal commands needed to train and load the models described in Section 5.2. The trained models are available at ['Trained transformer models for predicting traces of Frobenius mod 2 of elliptic curves with conductor up to 10^7'](https://zenodo.org/records/15839197).  The commands should be run from the Int2Int directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training command\n",
    "\n",
    "p = 97  # Choose a prime number\n",
    "\n",
    "python_name = 'python'  # Use your system's Python command (e.g., 'python', 'python3', or 'py')\n",
    "\n",
    "exp_name = f'apmod2_to_a{p}mod2_distinct_ecq7'  # Define experiment name \n",
    "\n",
    "exp_id_train = 1  # Set your experiment ID for training\n",
    "\n",
    "num_workers = 0  # Number of CPU workers\n",
    "\n",
    "data_folder = 'data/'  # Folder containing the training and test data\n",
    "\n",
    "train_cmd = f'{python_name} train.py --num_workers {num_workers} --dump_path scratch --exp_name {exp_name} --exp_id {exp_id_train} \\\n",
    "    --train_data {data_folder}/{exp_name}_train.txt --eval_data {data_folder}/{exp_name}_test.txt \\\n",
    "    --operation data --data_types int[24]:range(2) --env_base_seed 42 --architecture encoder_only \\\n",
    "    --epoch_size 100000 --optimizer adam,lr=0.00003 --eval_size 15000 --batch_size_eval 5000 --max_epoch 1001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the models\n",
    "\n",
    "exp_id_load = \"jan26\"  # Set your experiment ID for loading. For the experiments for predicting a_p mod 2 linked above, the IDs are jan26, jan27, or feb13, when the models were trained. \n",
    "\n",
    "checkpoint_name = \"periodic-1000\" # Name of the checkpoint. Usually \"checkpoint\", but if the periodic save was used in training, it can be e.g. \"periodic-100\"\n",
    "\n",
    "eval_verbose = True # Pick true to export detailed results of evaluation to scratch/{exp_name}/{exp_id_load}.\n",
    "\n",
    "load_cmd = f'{python_name} train.py --num_workers {num_workers} --dump_path scratch --exp_name {exp_name} --exp_id {exp_id_load} \\\n",
    "    --reload_model scratch/{exp_name}/{exp_id_train}/{checkpoint_name}.pth --reload_checkpoint scratch/{exp_name}/{exp_id_train}/{checkpoint_name}.pth \\\n",
    "    --eval_only True eval_verbose {eval_verbose} --eval_data {data_folder}/{exp_name}_test.txt \\\n",
    "    --operation data --data_types int[24]:range(2) --env_base_seed 42 --architecture encoder_only \\\n",
    "    --epoch_size 100000 --optimizer adam,lr=0.00003 --eval_size 15000 --batch_size_eval 5000 --max_epoch 1001'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
