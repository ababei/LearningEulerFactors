{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation for Section 5.1 Experiments\n",
    "\n",
    "This notebook generates the datasets used for training the experiments in **Section 5.1** for predicting $a_p \\bmod 2$ given the sequence $(a_q)_{q \\ne p,\\, q < 100}$.\n",
    "\n",
    "### Data Source\n",
    "\n",
    "The required data is loaded from the file [`ecq6.txt`](https://zenodo.org/records/15777475), which contains the sequence $(a_q)_{q < 100}$ for elliptic curves $E$ with conductor $N(E) < 10^7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and basic functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def encode_integer(val, base=1000, digit_sep=\" \"):\n",
    "    if val == 0:\n",
    "        return '+ 0'\n",
    "    sgn = '+' if val >= 0 else '-'\n",
    "    val = abs(val)\n",
    "    r = []\n",
    "    while val > 0:\n",
    "        r.append(str(val % base))\n",
    "        val = val//base\n",
    "    r.append(sgn)\n",
    "    r.reverse()\n",
    "    return digit_sep.join(r)\n",
    "\n",
    "def encode_integer_array(arr, base=1000, digit_sep=\" \"):\n",
    "    return ' '.join([encode_integer(x, base, digit_sep) for x in arr])\n",
    "    \n",
    "def encode_pinteger(val, p):\n",
    "    return '+ '+str(p)+str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix a random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Define the list of primes for the column names\n",
    "ps = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n",
    "\n",
    "# For each prime p, generate the dataset to predict a_p mod 2 \n",
    "for i, p in enumerate(ps):\n",
    "    print(f\"Prime is {p}\")\n",
    "    column_names =  ['a_' + str(q) for q in ps]\n",
    "\n",
    "    # Prepare to read the data\n",
    "    data = []\n",
    "\n",
    "    # Read from the file\n",
    "    with open(r\"ecq6.txt\", 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(':')\n",
    "            data.append(list(map(int, parts[7].strip('[]').split(',')))[:25])\n",
    "\n",
    "    # Create main dataframe df\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    df.dropna(inplace=True)\n",
    "    # encode all columns if not p \n",
    "    for q in ps:\n",
    "        if q != p:\n",
    "            df['a_' + str(q)] = df['a_' + str(q)].apply(lambda x: encode_integer(x % 2))\n",
    "        if q == p:\n",
    "            df['a_' + str(q)] = df['a_' + str(q)].apply(lambda x: encode_integer(x))\n",
    "\n",
    "    # input is all columns except the ith one\n",
    "    df['input'] = f\"V{len(ps)-1} \" + df.drop(columns=['a_' + str(p)]).astype(str).agg(' '.join, axis=1)\n",
    "    df['output'] = df['a_'+str(p)]\n",
    "    df = df[['input', 'output']]\n",
    "    \n",
    "    # Save the dataframe to a text file\n",
    "    # first create the directory if it does not exist\n",
    "    import os\n",
    "    directory = f\"raw_aps_but_{p}_to_a{p}_mod_2\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    df.to_csv(f\"{directory}/raw_aps_but_{p}_to_a{p}_mod_2.txt\", sep='\\t', index=False, header=False)\n",
    "    # train text split it \n",
    "    df_train, df_test = train_test_split(df, test_size=10000, random_state=seed, shuffle=True)\n",
    "    df_train = df_train[:2000000]\n",
    "    df_train.to_csv(f\"{directory}/raw_aps_but_{p}_to_a{p}_mod_2_train.txt\", sep='\\t', index=False, header=False)\n",
    "    df_test.to_csv(f\"{directory}/raw_aps_but_{p}_to_a{p}_mod_2_test.txt\", sep='\\t', index=False, header=False)\n",
    "\n",
    "    # Delete intermediate dataframes \n",
    "    del df\n",
    "    del df_train\n",
    "    del df_test\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
